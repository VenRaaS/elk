input {

#	file {
#		path => "/home/elk/data/model/all_AR_dump.tsv"
#		start_position => "beginning"
#		type => "ar_i2i"
#	}
	
	file {
		path => "/tmp/all_breadcrumb_dump_20171128.tsv"
		start_position => "beginning"
		type => "breadcrumb"
	}
	
#	file {
#		path => "/home/itri/data/all_CoOc_dump.tsv"
#		start_position => "beginning"
#		type => "cooc_i2i"
#	}
	
	file {
		path => "/tmp/all_GCF_dump_titantech_20171128.tsv"
		start_position => "beginning"
		type => "goods_category_flatten"
	}

#        file {
#                path => "/tmp/category_flatten.tsv"
#                start_position => "beginning"
#                type => "category_flatten"
#        }
	
	file {
		path => "/tmp/all_TP_dump_titantech_20171128.tsv"
		start_position => "beginning"
		type => "tp"
	}
	
#	file {
#		path => "/home/itri/data/all_VIG_dump.tsv"
#		start_position => "beginning"
#		type => "vig"
#	}
}

filter {
	grok {
#		match => { "path" => "%{NUMBER:[@metadata][date]}.tsv" }
		#-- extract date from the suffix of filename and set into [@metadata][date]
		#   https://www.elastic.co/guide/en/logstash/1.5/plugins-filters-grok.html#_custom_patterns
		match => { "path" => "(?<file_suffix_date>(19|20)\d\d(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])).tsv" }
		add_field => { "[@metadata][date]" => "%{file_suffix_date}" }
		remove_field => [ "file_suffix_date" ]
	}  

	if [type] == "tp"  {
		csv {
			columns => [ "code_name", "category_code", "indicators", "params", "indicators_raw", "update_time" ]
			separator => "	"
		}

		mutate {
			split => ["gids",","]
		}
	}

	if [type] == "vig" {
		csv {
			columns => [ "code_name", "gid", "score", "params", "update_time" ]
			separator => "	"
		}
	}

	if [type] == "goods_category_flatten" {
		csv {
			columns => [ "code_name", "id", "category_code", "le", "gid", "update_time" ]
			separator => "	"
		}
	}
	
        if [type] == "category_flatten" {
                csv {
                        columns => [ "code_name", "id", "ancestor", "category_code", "update_time" ]
                        separator => "  "
                }
        }	

	if [type] == "breadcrumb" {
		csv {
			columns => [ "code_name", "id", "gid", "breadcrumb", "update_time" ]
			separator => "	"
		}
	}

	if [type] == "cooc_i2i"  {
		csv {
			columns => [ "code_name", "gid", "indicators", "indicators_raw", "params",  "update_time" ]
			separator => "	"
		}

		mutate {
			split => ["indicators", ","]
		}
	}

	if [type] == "ar_i2i"  {
		csv {
			columns => [ "code_name", "gid", "consequents", "consequents_raw", "params", "update_time" ]
			separator => "	"
		}

		mutate {
			split => ["consequents", ","]
		}
	}
	
	if [type] == "tp_goods"  {
                csv {
                        columns => [ "code_name", "gid", "click_num", "order_num",  "update_time" ]
                        separator => "  "
                }
        }

	mutate {
		add_field => { "[@metadata][code_name]" => "%{code_name}" }
		add_field => { "[@metadata][type]" => "%{type}" }
		remove_field => [ "type", "code_name", "id", "message", "host", "path", "@version", "@timestamp", "file", "offset" ]
	}
}

output {
	elasticsearch { 
#		host => ["es-node-01:9300"]
		host => ["10.140.0.7:9300"]
		cluster => "westernwall"
                index => "%{[@metadata][code_name]}_mod_%{[@metadata][date]}"
		document_type => "%{[@metadata][type]}"
	}

#	stdout {
#		codec => rubydebug { metadata => true } 
##		codec => json 
#	}
	
}
